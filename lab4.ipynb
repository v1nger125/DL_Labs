{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.8\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "# я немного потанцевал с бубном, чтобы поставить версию питона пониже(нужна для tensorflow) и ничего не сломать, теперь начинаем лабу\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 8, 8, 1) (1797,)\n"
     ]
    }
   ],
   "source": [
    "# видео карта подтягиваться не захотела, как и я не захотел заморачиваться для учебного примера\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "import tensorflow as tf\n",
    "\n",
    "# данные по варианту\n",
    "digits = load_digits()\n",
    "digits['data'].shape\n",
    "\n",
    "data = digits['data']\n",
    "labels = digits['target']\n",
    "\n",
    "data = data.reshape(data.shape[0],8,8,1)\n",
    "print(data.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1797 1797\n"
     ]
    }
   ],
   "source": [
    "# данные из первой лабы + разделение на test train\n",
    "\n",
    "def TTVsplit(X, Y, TrainLen=0.70, TestLen=0.2):\n",
    "    if TrainLen+TestLen >= 1:\n",
    "        return\n",
    "    TrainLen = int(len(X)*TrainLen)\n",
    "    TestLen = int(len(X)*TestLen)\n",
    "\n",
    "    Xtrain = X[:TrainLen]\n",
    "    Xtest = X[TrainLen:TrainLen+TestLen]\n",
    "    Xval = X[TrainLen+TestLen:]\n",
    "    Ytrain = Y[:TrainLen]\n",
    "    Ytest = Y[TrainLen:TrainLen+TestLen]\n",
    "    Yval = Y[TrainLen+TestLen:]\n",
    "    \n",
    "    return Xtrain, Xtest, Xval, Ytrain, Ytest, Yval\n",
    "\n",
    "Xtrain, Xtest, Xval, Ytrain, Ytest, Yval = TTVsplit(data.copy(), labels.copy())\n",
    "print(len(Xtrain)+len(Xtest)+len(Xval), len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    def __init__(self, X, y, batch_size, shuffle=False):\n",
    "        \"\"\"\n",
    "        Construct a Dataset object to iterate over data X and labels y\n",
    "        \n",
    "        Inputs:\n",
    "        - X: Numpy array of data, of any shape\n",
    "        - y: Numpy array of labels, of any shape but with y.shape[0] == X.shape[0]\n",
    "        - batch_size: Integer giving number of elements per minibatch\n",
    "        - shuffle: (optional) Boolean, whether to shuffle the data on each epoch\n",
    "        \"\"\"\n",
    "        assert X.shape[0] == y.shape[0], 'Got different numbers of data and labels'\n",
    "        self.X, self.y = X, y\n",
    "        self.batch_size, self.shuffle = batch_size, shuffle\n",
    "\n",
    "    def __iter__(self):\n",
    "        N, B = self.X.shape[0], self.batch_size\n",
    "        idxs = np.arange(N)\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(idxs)\n",
    "        return iter((self.X[i:i+B], self.y[i:i+B]) for i in range(0, N, B))\n",
    "\n",
    "\n",
    "train_dset = Dataset(Xtrain, Ytrain, batch_size=64, shuffle=True)\n",
    "val_dset = Dataset(Xval, Yval, batch_size=64, shuffle=False)\n",
    "test_dset = Dataset(Xtest, Ytest, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 10)\n"
     ]
    }
   ],
   "source": [
    "# тестовый пример из методички\n",
    "class TwoLayerFC(tf.keras.Model):\n",
    "    def __init__(self, hidden_size, num_classes):\n",
    "        super(TwoLayerFC, self).__init__()        \n",
    "        initializer = tf.initializers.VarianceScaling(scale=2.0)\n",
    "        self.fc1 = tf.keras.layers.Dense(hidden_size, activation='relu',\n",
    "                                   kernel_initializer=initializer)\n",
    "        self.fc2 = tf.keras.layers.Dense(num_classes, activation='softmax',\n",
    "                                   kernel_initializer=initializer)\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "    \n",
    "    def call(self, x, training=False):\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def test_TwoLayerFC():\n",
    "    \"\"\" A small unit test to exercise the TwoLayerFC model above. \"\"\"\n",
    "    input_size, hidden_size, num_classes = 50, 42, 10\n",
    "    x = tf.zeros((64, input_size))\n",
    "    model = TwoLayerFC(hidden_size, num_classes)\n",
    "    scores = model(x)\n",
    "    print(scores.shape)\n",
    "        \n",
    "test_TwoLayerFC()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте трехслойную CNN для вашей задачи классификации.\n",
    "\n",
    "Архитектура сети:\n",
    "\n",
    "1. Сверточный слой (5 x 5 kernels, zero-padding = 'same')\n",
    "2. Функция активации ReLU\n",
    "3. Сверточный слой (3 x 3 kernels, zero-padding = 'same')\n",
    "4. Функция активации ReLU\n",
    "5. Полносвязный слой\n",
    "6. Функция активации Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# реализация первого задания\n",
    "class ThreeLayerConvNet(tf.keras.Model):\n",
    "    def __init__(self, channel_1, channel_2, num_classes):\n",
    "        super(ThreeLayerConvNet, self).__init__()\n",
    "        ########################################################################\n",
    "        # TODO: Implement the __init__ method for a three-layer ConvNet. You   #\n",
    "        # should instantiate layer objects to be used in the forward pass.     #\n",
    "        ########################################################################\n",
    "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "        self.conv1 = tf.keras.layers.Conv2D(channel_1, 5, activation=\"relu\", padding=\"same\")\n",
    "        self.conv2 = tf.keras.layers.Conv2D(channel_2, 3, activation=\"relu\", padding=\"same\")\n",
    "        \n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.fc1 = tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "\n",
    "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "        ########################################################################\n",
    "        #                           END OF YOUR CODE                           #\n",
    "        ########################################################################\n",
    "        \n",
    "    def call(self, x, training=False):\n",
    "        scores = None\n",
    "        ########################################################################\n",
    "        # TODO: Implement the forward pass for a three-layer ConvNet. You      #\n",
    "        # should use the layer objects defined in the __init__ method.         #\n",
    "        ########################################################################\n",
    "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.flatten(x)\n",
    "        scores = self.fc1(x)\n",
    "\n",
    "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "        ########################################################################\n",
    "        #                           END OF YOUR CODE                           #\n",
    "        ########################################################################        \n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 10)\n"
     ]
    }
   ],
   "source": [
    "def test_ThreeLayerConvNet():    \n",
    "    channel_1, channel_2, num_classes = 12, 8, 10\n",
    "    model = ThreeLayerConvNet(channel_1, channel_2, num_classes)\n",
    "    x = tf.zeros((64, 3, 32, 32))\n",
    "    scores = model(x)\n",
    "    print(scores.shape)\n",
    "\n",
    "test_ThreeLayerConvNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_part34(model_init_fn, optimizer_init_fn, num_epochs=1, is_training=False, print_every=5):\n",
    "    \"\"\"\n",
    "    Simple training loop for use with models defined using tf.keras. It trains\n",
    "    a model for one epoch on the CIFAR-10 training set and periodically checks\n",
    "    accuracy on the CIFAR-10 validation set.\n",
    "    \n",
    "    Inputs:\n",
    "    - model_init_fn: A function that takes no parameters; when called it\n",
    "      constructs the model we want to train: model = model_init_fn()\n",
    "    - optimizer_init_fn: A function which takes no parameters; when called it\n",
    "      constructs the Optimizer object we will use to optimize the model:\n",
    "      optimizer = optimizer_init_fn()\n",
    "    - num_epochs: The number of epochs to train for\n",
    "    \n",
    "    Returns: Nothing, but prints progress during trainingn\n",
    "    \"\"\"    \n",
    "\n",
    "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "    model = model_init_fn()\n",
    "    optimizer = optimizer_init_fn()\n",
    "\n",
    "    train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "    train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "    val_loss = tf.keras.metrics.Mean(name='val_loss')\n",
    "    val_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='val_accuracy')\n",
    "\n",
    "    t = 0\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        # Reset the metrics - https://www.tensorflow.org/alpha/guide/migration_guide#new-style_metrics\n",
    "        train_loss.reset_states()\n",
    "        train_accuracy.reset_states()\n",
    "\n",
    "        for x_np, y_np in train_dset:\n",
    "            with tf.GradientTape() as tape:\n",
    "\n",
    "                # Use the model function to build the forward pass.\n",
    "                scores = model(x_np, training=is_training)\n",
    "                loss = loss_fn(y_np, scores)\n",
    "\n",
    "                gradients = tape.gradient(loss, model.trainable_variables)\n",
    "                optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "                # Update the metrics\n",
    "                train_loss.update_state(loss)\n",
    "                train_accuracy.update_state(y_np, scores)\n",
    "\n",
    "                if t % print_every == 0:\n",
    "                    val_loss.reset_states()\n",
    "                    val_accuracy.reset_states()\n",
    "                    for test_x, test_y in val_dset:\n",
    "                        # During validation at end of epoch, training set to False\n",
    "                        prediction = model(test_x, training=False)\n",
    "                        t_loss = loss_fn(test_y, prediction)\n",
    "\n",
    "                        val_loss.update_state(t_loss)\n",
    "                        val_accuracy.update_state(test_y, prediction)\n",
    "\n",
    "                    template = 'Iteration {}, Epoch {}, Loss: {}, Accuracy: {}, Val Loss: {}, Val Accuracy: {}'\n",
    "                    print (template.format(t, epoch+1,\n",
    "                                         train_loss.result(),\n",
    "                                         train_accuracy.result()*100,\n",
    "                                         val_loss.result(),\n",
    "                                         val_accuracy.result()*100))\n",
    "                t += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Epoch 1, Loss: 15.266045570373535, Accuracy: 6.25, Val Loss: 11.106541633605957, Val Accuracy: 14.364640235900879\n",
      "Iteration 5, Epoch 1, Loss: 8.279751777648926, Accuracy: 25.0, Val Loss: 5.2058329582214355, Val Accuracy: 44.19889450073242\n",
      "Iteration 10, Epoch 1, Loss: 6.052606582641602, Accuracy: 31.960227966308594, Val Loss: 3.3001291751861572, Val Accuracy: 49.17127227783203\n",
      "Iteration 15, Epoch 1, Loss: 4.7568182945251465, Accuracy: 41.6015625, Val Loss: 2.1563313007354736, Val Accuracy: 65.19337463378906\n",
      "Iteration 20, Epoch 2, Loss: 1.5685036182403564, Accuracy: 71.875, Val Loss: 1.5655149221420288, Val Accuracy: 70.71823120117188\n",
      "Iteration 25, Epoch 2, Loss: 0.6139066815376282, Accuracy: 84.89582824707031, Val Loss: 1.2553088665008545, Val Accuracy: 77.34806823730469\n",
      "Iteration 30, Epoch 2, Loss: 0.5942705273628235, Accuracy: 84.09090423583984, Val Loss: 1.278493046760559, Val Accuracy: 76.24309539794922\n",
      "Iteration 35, Epoch 2, Loss: 0.541005551815033, Accuracy: 85.15625, Val Loss: 1.4884716272354126, Val Accuracy: 70.71823120117188\n",
      "Iteration 40, Epoch 3, Loss: 1.1998878717422485, Accuracy: 78.125, Val Loss: 1.0988315343856812, Val Accuracy: 77.90055084228516\n",
      "Iteration 45, Epoch 3, Loss: 0.39624810218811035, Accuracy: 90.36457824707031, Val Loss: 1.032485008239746, Val Accuracy: 81.76795959472656\n",
      "Iteration 50, Epoch 3, Loss: 0.36375170946121216, Accuracy: 89.48863983154297, Val Loss: 1.1362274885177612, Val Accuracy: 75.69061279296875\n",
      "Iteration 55, Epoch 3, Loss: 0.3251841962337494, Accuracy: 90.234375, Val Loss: 1.1743918657302856, Val Accuracy: 78.45304107666016\n",
      "Iteration 60, Epoch 4, Loss: 0.8779225945472717, Accuracy: 84.375, Val Loss: 0.9394620060920715, Val Accuracy: 82.32044219970703\n",
      "Iteration 65, Epoch 4, Loss: 0.29026904702186584, Accuracy: 93.48957824707031, Val Loss: 0.9522656798362732, Val Accuracy: 82.32044219970703\n",
      "Iteration 70, Epoch 4, Loss: 0.267438679933548, Accuracy: 93.18181610107422, Val Loss: 1.0213773250579834, Val Accuracy: 78.45304107666016\n",
      "Iteration 75, Epoch 4, Loss: 0.24036820232868195, Accuracy: 93.45703125, Val Loss: 1.0110692977905273, Val Accuracy: 82.8729248046875\n",
      "Iteration 80, Epoch 5, Loss: 0.669813871383667, Accuracy: 85.9375, Val Loss: 0.8660220503807068, Val Accuracy: 83.4254150390625\n",
      "Iteration 85, Epoch 5, Loss: 0.22809219360351562, Accuracy: 93.48957824707031, Val Loss: 0.8993209004402161, Val Accuracy: 82.8729248046875\n",
      "Iteration 90, Epoch 5, Loss: 0.2104330211877823, Accuracy: 94.31818389892578, Val Loss: 0.9304203987121582, Val Accuracy: 81.21546936035156\n",
      "Iteration 95, Epoch 5, Loss: 0.18960249423980713, Accuracy: 94.53125, Val Loss: 0.92502361536026, Val Accuracy: 85.08287048339844\n",
      "Iteration 100, Epoch 6, Loss: 0.5149946212768555, Accuracy: 89.0625, Val Loss: 0.822374165058136, Val Accuracy: 83.9779052734375\n",
      "Iteration 105, Epoch 6, Loss: 0.18270568549633026, Accuracy: 95.3125, Val Loss: 0.853878915309906, Val Accuracy: 84.53038787841797\n",
      "Iteration 110, Epoch 6, Loss: 0.17058388888835907, Accuracy: 95.45454406738281, Val Loss: 0.8446157574653625, Val Accuracy: 83.9779052734375\n",
      "Iteration 115, Epoch 6, Loss: 0.15412241220474243, Accuracy: 95.703125, Val Loss: 0.868091881275177, Val Accuracy: 85.63536071777344\n",
      "Iteration 120, Epoch 7, Loss: 0.4017328917980194, Accuracy: 92.1875, Val Loss: 0.7827351689338684, Val Accuracy: 83.9779052734375\n",
      "Iteration 125, Epoch 7, Loss: 0.149966761469841, Accuracy: 95.83332824707031, Val Loss: 0.8114797472953796, Val Accuracy: 83.9779052734375\n",
      "Iteration 130, Epoch 7, Loss: 0.14227445423603058, Accuracy: 96.0227279663086, Val Loss: 0.7767097353935242, Val Accuracy: 84.53038787841797\n",
      "Iteration 135, Epoch 7, Loss: 0.12863028049468994, Accuracy: 96.2890625, Val Loss: 0.8221020698547363, Val Accuracy: 85.63536071777344\n",
      "Iteration 140, Epoch 8, Loss: 0.3199886679649353, Accuracy: 92.1875, Val Loss: 0.7517535090446472, Val Accuracy: 85.08287048339844\n",
      "Iteration 145, Epoch 8, Loss: 0.1259172260761261, Accuracy: 95.83332824707031, Val Loss: 0.774440348148346, Val Accuracy: 84.53038787841797\n",
      "Iteration 150, Epoch 8, Loss: 0.12138359993696213, Accuracy: 96.59090423583984, Val Loss: 0.7261984944343567, Val Accuracy: 83.9779052734375\n",
      "Iteration 155, Epoch 8, Loss: 0.1098688393831253, Accuracy: 96.77734375, Val Loss: 0.7800001502037048, Val Accuracy: 85.63536071777344\n",
      "Iteration 160, Epoch 9, Loss: 0.25694045424461365, Accuracy: 92.1875, Val Loss: 0.7234882712364197, Val Accuracy: 85.63536071777344\n",
      "Iteration 165, Epoch 9, Loss: 0.1077888086438179, Accuracy: 96.09375, Val Loss: 0.740649402141571, Val Accuracy: 85.08287048339844\n",
      "Iteration 170, Epoch 9, Loss: 0.1054934710264206, Accuracy: 96.73295593261719, Val Loss: 0.6875190734863281, Val Accuracy: 83.9779052734375\n",
      "Iteration 175, Epoch 9, Loss: 0.09544643014669418, Accuracy: 96.875, Val Loss: 0.7418674826622009, Val Accuracy: 86.1878433227539\n",
      "Iteration 180, Epoch 10, Loss: 0.20819474756717682, Accuracy: 95.3125, Val Loss: 0.701394259929657, Val Accuracy: 85.63536071777344\n",
      "Iteration 185, Epoch 10, Loss: 0.0936838909983635, Accuracy: 96.61457824707031, Val Loss: 0.712745726108551, Val Accuracy: 85.63536071777344\n",
      "Iteration 190, Epoch 10, Loss: 0.09264814108610153, Accuracy: 97.15909576416016, Val Loss: 0.659541130065918, Val Accuracy: 83.9779052734375\n",
      "Iteration 195, Epoch 10, Loss: 0.08397801965475082, Accuracy: 97.36328125, Val Loss: 0.7103106379508972, Val Accuracy: 86.1878433227539\n"
     ]
    }
   ],
   "source": [
    "hidden_size, num_classes = 100, 10\n",
    "learning_rate = 1e-2\n",
    "\n",
    "def model_init_fn():\n",
    "    return TwoLayerFC(hidden_size, num_classes)\n",
    "\n",
    "def optimizer_init_fn():\n",
    "    return tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "\n",
    "train_part34(model_init_fn, optimizer_init_fn, num_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите трехслойную CNN. В tf.keras.optimizers.SGD укажите Nesterov momentum = 0.9.  \n",
    "\n",
    "https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/optimizers/SGD  \n",
    "\n",
    "Значение accuracy на валидационной выборке после 1 эпохи обучения должно быть > 50%.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Epoch 1, Loss: 2.8431551456451416, Accuracy: 18.75, Val Loss: 2.367692232131958, Val Accuracy: 18.232044219970703\n",
      "Iteration 5, Epoch 1, Loss: 1.987907886505127, Accuracy: 36.71875, Val Loss: 1.2818776369094849, Val Accuracy: 69.6132583618164\n",
      "Iteration 10, Epoch 1, Loss: 1.598429799079895, Accuracy: 51.42045593261719, Val Loss: 0.7685322761535645, Val Accuracy: 79.5580062866211\n",
      "Iteration 15, Epoch 1, Loss: 1.2831567525863647, Accuracy: 61.62109375, Val Loss: 0.7430081963539124, Val Accuracy: 83.4254150390625\n",
      "Iteration 20, Epoch 2, Loss: 0.5372335910797119, Accuracy: 85.9375, Val Loss: 0.4340353310108185, Val Accuracy: 85.08287048339844\n",
      "Iteration 25, Epoch 2, Loss: 0.4097951352596283, Accuracy: 89.58332824707031, Val Loss: 0.5003913044929504, Val Accuracy: 86.1878433227539\n",
      "Iteration 30, Epoch 2, Loss: 0.358908087015152, Accuracy: 90.48295593261719, Val Loss: 0.48282989859580994, Val Accuracy: 87.2928237915039\n",
      "Iteration 35, Epoch 2, Loss: 0.3299383819103241, Accuracy: 91.2109375, Val Loss: 0.6448836922645569, Val Accuracy: 82.8729248046875\n",
      "Iteration 40, Epoch 3, Loss: 0.25259044766426086, Accuracy: 89.0625, Val Loss: 0.3785465955734253, Val Accuracy: 90.05525207519531\n",
      "Iteration 45, Epoch 3, Loss: 0.15467508137226105, Accuracy: 93.75, Val Loss: 0.3346071243286133, Val Accuracy: 90.05525207519531\n",
      "Iteration 50, Epoch 3, Loss: 0.1489560753107071, Accuracy: 94.74431610107422, Val Loss: 0.36607304215431213, Val Accuracy: 90.05525207519531\n",
      "Iteration 55, Epoch 3, Loss: 0.14253027737140656, Accuracy: 95.1171875, Val Loss: 0.4931528568267822, Val Accuracy: 86.1878433227539\n",
      "Iteration 60, Epoch 4, Loss: 0.21731065213680267, Accuracy: 90.625, Val Loss: 0.3801392614841461, Val Accuracy: 90.05525207519531\n",
      "Iteration 65, Epoch 4, Loss: 0.10205665975809097, Accuracy: 96.09375, Val Loss: 0.3841552436351776, Val Accuracy: 90.05525207519531\n",
      "Iteration 70, Epoch 4, Loss: 0.09555867314338684, Accuracy: 97.01704406738281, Val Loss: 0.372550368309021, Val Accuracy: 90.60773468017578\n",
      "Iteration 75, Epoch 4, Loss: 0.09556867927312851, Accuracy: 97.16796875, Val Loss: 0.4983017146587372, Val Accuracy: 87.2928237915039\n",
      "Iteration 80, Epoch 5, Loss: 0.10253912210464478, Accuracy: 96.875, Val Loss: 0.40987300872802734, Val Accuracy: 90.05525207519531\n",
      "Iteration 85, Epoch 5, Loss: 0.06368642300367355, Accuracy: 98.69792175292969, Val Loss: 0.4065796136856079, Val Accuracy: 90.60773468017578\n",
      "Iteration 90, Epoch 5, Loss: 0.0791933611035347, Accuracy: 98.01136016845703, Val Loss: 0.40060436725616455, Val Accuracy: 90.60773468017578\n",
      "Iteration 95, Epoch 5, Loss: 0.08207692950963974, Accuracy: 97.75390625, Val Loss: 0.4619256556034088, Val Accuracy: 88.39778900146484\n",
      "Iteration 100, Epoch 6, Loss: 0.06343749910593033, Accuracy: 98.4375, Val Loss: 0.4418618679046631, Val Accuracy: 91.16021728515625\n",
      "Iteration 105, Epoch 6, Loss: 0.052471745759248734, Accuracy: 98.69792175292969, Val Loss: 0.4345523416996002, Val Accuracy: 90.05525207519531\n",
      "Iteration 110, Epoch 6, Loss: 0.06728523969650269, Accuracy: 98.15340423583984, Val Loss: 0.36562368273735046, Val Accuracy: 90.05525207519531\n",
      "Iteration 115, Epoch 6, Loss: 0.06662468612194061, Accuracy: 97.8515625, Val Loss: 0.43690815567970276, Val Accuracy: 88.39778900146484\n",
      "Iteration 120, Epoch 7, Loss: 0.05429458245635033, Accuracy: 100.0, Val Loss: 0.4445796310901642, Val Accuracy: 91.16021728515625\n",
      "Iteration 125, Epoch 7, Loss: 0.040776778012514114, Accuracy: 99.21875, Val Loss: 0.4399026334285736, Val Accuracy: 88.95027923583984\n",
      "Iteration 130, Epoch 7, Loss: 0.05450664460659027, Accuracy: 98.57954406738281, Val Loss: 0.3574008643627167, Val Accuracy: 90.60773468017578\n",
      "Iteration 135, Epoch 7, Loss: 0.04977372661232948, Accuracy: 98.6328125, Val Loss: 0.39749574661254883, Val Accuracy: 90.05525207519531\n",
      "Iteration 140, Epoch 8, Loss: 0.055106811225414276, Accuracy: 98.4375, Val Loss: 0.43337276577949524, Val Accuracy: 91.71270751953125\n",
      "Iteration 145, Epoch 8, Loss: 0.03274731710553169, Accuracy: 99.21875, Val Loss: 0.4412381649017334, Val Accuracy: 91.16021728515625\n",
      "Iteration 150, Epoch 8, Loss: 0.03777429834008217, Accuracy: 99.1477279663086, Val Loss: 0.38319745659828186, Val Accuracy: 90.60773468017578\n",
      "Iteration 155, Epoch 8, Loss: 0.03600896894931793, Accuracy: 99.12109375, Val Loss: 0.3898460865020752, Val Accuracy: 90.05525207519531\n",
      "Iteration 160, Epoch 9, Loss: 0.055702924728393555, Accuracy: 100.0, Val Loss: 0.4388253390789032, Val Accuracy: 90.05525207519531\n",
      "Iteration 165, Epoch 9, Loss: 0.030135804787278175, Accuracy: 99.21875, Val Loss: 0.45236918330192566, Val Accuracy: 91.71270751953125\n",
      "Iteration 170, Epoch 9, Loss: 0.03208426758646965, Accuracy: 99.2897720336914, Val Loss: 0.39930155873298645, Val Accuracy: 90.05525207519531\n",
      "Iteration 175, Epoch 9, Loss: 0.03036576509475708, Accuracy: 99.31640625, Val Loss: 0.3865531384944916, Val Accuracy: 92.26519775390625\n",
      "Iteration 180, Epoch 10, Loss: 0.040534306317567825, Accuracy: 100.0, Val Loss: 0.44040465354919434, Val Accuracy: 90.60773468017578\n",
      "Iteration 185, Epoch 10, Loss: 0.025233961641788483, Accuracy: 99.47917175292969, Val Loss: 0.4306049346923828, Val Accuracy: 91.71270751953125\n",
      "Iteration 190, Epoch 10, Loss: 0.024496369063854218, Accuracy: 99.71590423583984, Val Loss: 0.40136221051216125, Val Accuracy: 91.71270751953125\n",
      "Iteration 195, Epoch 10, Loss: 0.02346961200237274, Accuracy: 99.8046875, Val Loss: 0.40218451619148254, Val Accuracy: 91.71270751953125\n"
     ]
    }
   ],
   "source": [
    "# Done точность после первой эпохи больше 50% \n",
    "learning_rate = 3e-3\n",
    "channel_1, channel_2, num_classes = 32, 16, 10\n",
    "\n",
    "def model_init_fn():\n",
    "    model = None\n",
    "    ############################################################################\n",
    "    # TODO: Complete the implementation of model_fn.                           #\n",
    "    ############################################################################\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "    model = ThreeLayerConvNet(channel_1, channel_2, num_classes) \n",
    "\n",
    "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    ############################################################################\n",
    "    #                           END OF YOUR CODE                               #\n",
    "    ############################################################################\n",
    "    return model\n",
    "\n",
    "def optimizer_init_fn():\n",
    "    optimizer = None\n",
    "    ############################################################################\n",
    "    # TODO: Complete the implementation of model_fn.                           #\n",
    "    ############################################################################\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9, nesterov=True)\n",
    "\n",
    "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    ############################################################################\n",
    "    #                           END OF YOUR CODE                               #\n",
    "    ############################################################################\n",
    "    return optimizer\n",
    "\n",
    "train_part34(model_init_fn, optimizer_init_fn, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Epoch 1, Loss: 14.897880554199219, Accuracy: 6.25, Val Loss: 11.6000394821167, Val Accuracy: 13.259668350219727\n",
      "Iteration 5, Epoch 1, Loss: 9.239715576171875, Accuracy: 15.104166984558105, Val Loss: 4.56206750869751, Val Accuracy: 28.176795959472656\n",
      "Iteration 10, Epoch 1, Loss: 7.1071624755859375, Accuracy: 23.863636016845703, Val Loss: 3.50581955909729, Val Accuracy: 46.40884017944336\n",
      "Iteration 15, Epoch 1, Loss: 5.724612236022949, Accuracy: 32.2265625, Val Loss: 2.499690294265747, Val Accuracy: 54.14365005493164\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-2\n",
    "\n",
    "def model_init_fn():\n",
    "    input_shape = (8, 8, 1)\n",
    "    hidden_layer_size, num_classes = 100, 10\n",
    "    initializer = tf.initializers.VarianceScaling(scale=2.0)\n",
    "    layers = [\n",
    "        tf.keras.layers.Flatten(input_shape=input_shape),\n",
    "        tf.keras.layers.Dense(hidden_layer_size, activation='relu',\n",
    "                              kernel_initializer=initializer),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax', \n",
    "                              kernel_initializer=initializer),\n",
    "    ]\n",
    "    model = tf.keras.Sequential(layers)\n",
    "    return model\n",
    "\n",
    "def optimizer_init_fn():\n",
    "    return tf.keras.optimizers.SGD(learning_rate=learning_rate) \n",
    "\n",
    "train_part34(model_init_fn, optimizer_init_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 1s 24ms/step - loss: 7.7397 - sparse_categorical_accuracy: 0.3005 - val_loss: 1.2418 - val_sparse_categorical_accuracy: 0.7238\n",
      "12/12 [==============================] - 0s 637us/step - loss: 1.2916 - sparse_categorical_accuracy: 0.7159\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.291609287261963, 0.7158774137496948]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model_init_fn()\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=learning_rate),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=[tf.keras.metrics.sparse_categorical_accuracy])\n",
    "model.fit(Xtrain, Ytrain, batch_size=64, epochs=1, validation_data=(Xval, Yval))\n",
    "model.evaluate(Xtest, Ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перепишите реализацию трехслойной CNN с помощью tf.keras.Sequential API . Обучите модель двумя способами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Epoch 1, Loss: 3.376075506210327, Accuracy: 10.9375, Val Loss: 3.0269925594329834, Val Accuracy: 13.812154769897461\n",
      "Iteration 5, Epoch 1, Loss: 2.8099453449249268, Accuracy: 17.96875, Val Loss: 2.310694932937622, Val Accuracy: 14.91712760925293\n",
      "Iteration 10, Epoch 1, Loss: 2.560102939605713, Accuracy: 18.18181800842285, Val Loss: 2.0563642978668213, Val Accuracy: 33.70166015625\n",
      "Iteration 15, Epoch 1, Loss: 2.3867783546447754, Accuracy: 21.6796875, Val Loss: 1.7848691940307617, Val Accuracy: 46.961326599121094\n"
     ]
    }
   ],
   "source": [
    "def model_init_fn():\n",
    "    model = None\n",
    "    ############################################################################\n",
    "    # TODO: Construct a three-layer ConvNet using tf.keras.Sequential.         #\n",
    "    ############################################################################\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "    input_shape = (8,8,1)\n",
    "    channel_1, channel_2, num_classes = 32, 16, 10\n",
    "    layers = [\n",
    "        tf.keras.layers.Conv2D(channel_1, 5, activation=\"relu\", padding=\"same\", input_shape=input_shape),\n",
    "        tf.keras.layers.Conv2D(channel_2, 3, activation=\"relu\", padding=\"same\"),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ]\n",
    "    model = tf.keras.Sequential(layers)\n",
    "\n",
    "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    ############################################################################\n",
    "    #                            END OF YOUR CODE                              #\n",
    "    ############################################################################\n",
    "    return model\n",
    "\n",
    "learning_rate = 5e-4\n",
    "def optimizer_init_fn():\n",
    "    optimizer = None\n",
    "    ############################################################################\n",
    "    # TODO: Complete the implementation of model_fn.                           #\n",
    "    ############################################################################\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9, nesterov=True)\n",
    "\n",
    "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    ############################################################################\n",
    "    #                           END OF YOUR CODE                               #\n",
    "    ############################################################################\n",
    "    return optimizer\n",
    "\n",
    "train_part34(model_init_fn, optimizer_init_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "20/20 [==============================] - 1s 18ms/step - loss: 1.8130 - sparse_categorical_accuracy: 0.3989 - val_loss: 0.6415 - val_sparse_categorical_accuracy: 0.8287\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.4284 - sparse_categorical_accuracy: 0.8972 - val_loss: 0.4193 - val_sparse_categorical_accuracy: 0.8895\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.1969 - sparse_categorical_accuracy: 0.9525 - val_loss: 0.3497 - val_sparse_categorical_accuracy: 0.9006\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.1611 - sparse_categorical_accuracy: 0.9502 - val_loss: 0.2942 - val_sparse_categorical_accuracy: 0.9171\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.1462 - sparse_categorical_accuracy: 0.9574 - val_loss: 0.3076 - val_sparse_categorical_accuracy: 0.9116\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3140 - sparse_categorical_accuracy: 0.8997\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.31401145458221436, 0.8997214436531067]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model_init_fn()\n",
    "model.compile(optimizer='sgd',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=[tf.keras.metrics.sparse_categorical_accuracy])\n",
    "model.fit(Xtrain, Ytrain, batch_size=64, epochs=5, validation_data=(Xval, Yval))\n",
    "model.evaluate(Xtest, Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 10)\n"
     ]
    }
   ],
   "source": [
    "def two_layer_fc_functional(input_shape, hidden_size, num_classes):  \n",
    "    initializer = tf.initializers.VarianceScaling(scale=2.0)\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    flattened_inputs = tf.keras.layers.Flatten()(inputs)\n",
    "    fc1_output = tf.keras.layers.Dense(hidden_size, activation='relu',\n",
    "                                 kernel_initializer=initializer)(flattened_inputs)\n",
    "    scores = tf.keras.layers.Dense(num_classes, activation='softmax',\n",
    "                             kernel_initializer=initializer)(fc1_output)\n",
    "\n",
    "    # Instantiate the model given inputs and outputs.\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=scores)\n",
    "    return model\n",
    "\n",
    "def test_two_layer_fc_functional():\n",
    "    \"\"\" A small unit test to exercise the TwoLayerFC model above. \"\"\"\n",
    "    input_size, hidden_size, num_classes = 50, 42, 10\n",
    "    input_shape = (50,)\n",
    "    \n",
    "    x = tf.zeros((64, input_size))\n",
    "    model = two_layer_fc_functional(input_shape, hidden_size, num_classes)\n",
    "    \n",
    "    scores = model(x)\n",
    "    print(scores.shape)\n",
    "        \n",
    "test_two_layer_fc_functional()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Epoch 1, Loss: 13.2677640914917, Accuracy: 9.375, Val Loss: 9.635778427124023, Val Accuracy: 14.91712760925293\n",
      "Iteration 5, Epoch 1, Loss: 7.625944137573242, Accuracy: 22.395832061767578, Val Loss: 3.6998202800750732, Val Accuracy: 41.98895263671875\n",
      "Iteration 10, Epoch 1, Loss: 5.133203506469727, Accuracy: 37.21590805053711, Val Loss: 2.4154751300811768, Val Accuracy: 54.14365005493164\n",
      "Iteration 15, Epoch 1, Loss: 3.9574062824249268, Accuracy: 46.38671875, Val Loss: 1.8586149215698242, Val Accuracy: 63.535911560058594\n"
     ]
    }
   ],
   "source": [
    "input_shape = (8, 8, 1)\n",
    "hidden_size, num_classes = 100, 10\n",
    "learning_rate = 1e-2\n",
    "\n",
    "def model_init_fn():\n",
    "    return two_layer_fc_functional(input_shape, hidden_size, num_classes)\n",
    "\n",
    "def optimizer_init_fn():\n",
    "    return tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "\n",
    "train_part34(model_init_fn, optimizer_init_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поэкспериментируйте с архитектурой сверточной сети. Для вашего набора данных вам необходимо получить как минимум 70% accuracy на валидационной выборке за 10 эпох обучения. Опишите все эксперименты и сделайте выводы (без выполнения данного пункта работы приниматься не будут).  \n",
    "\n",
    "Эспериментируйте с архитектурой, гиперпараметрами, функцией потерь, регуляризацией, методом оптимизации.  \n",
    "\n",
    "https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/BatchNormalization#methods https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/Dropout#methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Epoch 1, Loss: 2.8871426582336426, Accuracy: 28.125, Val Loss: 2.40006422996521, Val Accuracy: 20.44198989868164\n",
      "Iteration 20, Epoch 2, Loss: 0.404843270778656, Accuracy: 90.625, Val Loss: 0.5591102242469788, Val Accuracy: 86.7403335571289\n",
      "Iteration 40, Epoch 3, Loss: 0.1670638769865036, Accuracy: 95.3125, Val Loss: 0.49945151805877686, Val Accuracy: 87.84529876708984\n",
      "Iteration 60, Epoch 4, Loss: 0.12048865109682083, Accuracy: 96.875, Val Loss: 0.539639413356781, Val Accuracy: 88.39778900146484\n",
      "Iteration 80, Epoch 5, Loss: 0.1582545042037964, Accuracy: 93.75, Val Loss: 0.5336039066314697, Val Accuracy: 88.39778900146484\n",
      "Iteration 100, Epoch 6, Loss: 0.1266362965106964, Accuracy: 95.3125, Val Loss: 0.42647144198417664, Val Accuracy: 89.50276184082031\n",
      "Iteration 120, Epoch 7, Loss: 0.061855778098106384, Accuracy: 98.4375, Val Loss: 0.3279155492782593, Val Accuracy: 92.81768035888672\n",
      "Iteration 140, Epoch 8, Loss: 0.06636713445186615, Accuracy: 98.4375, Val Loss: 0.3508599102497101, Val Accuracy: 93.37016296386719\n",
      "Iteration 160, Epoch 9, Loss: 0.04267449676990509, Accuracy: 96.875, Val Loss: 0.34016430377960205, Val Accuracy: 93.37016296386719\n",
      "Iteration 180, Epoch 10, Loss: 0.026441842317581177, Accuracy: 98.4375, Val Loss: 0.35480812191963196, Val Accuracy: 93.37016296386719\n"
     ]
    }
   ],
   "source": [
    "# РУБРИКА ЭКПЕРИМЕНТЫ\n",
    "# в общем начну с модели сделанной в работе и попробую добить точность до ~97, как было на простых классификаторах\n",
    "\n",
    "def model_init_fn():\n",
    "    input_shape = (8,8,1)\n",
    "    channel_1, channel_2, num_classes = 32, 16, 10\n",
    "    layers = [\n",
    "        tf.keras.layers.Conv2D(channel_1, 5, activation=\"relu\", padding=\"same\", input_shape=input_shape),\n",
    "        tf.keras.layers.Conv2D(channel_2, 3, activation=\"relu\", padding=\"same\"),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ]\n",
    "    model = tf.keras.Sequential(layers)\n",
    "    return model\n",
    "\n",
    "def optimizer_init_fn():\n",
    "    learning_rate = 1e-3\n",
    "    return tf.keras.optimizers.Adam(learning_rate) \n",
    "\n",
    "train_part34(model_init_fn, optimizer_init_fn, num_epochs=10, is_training=True, print_every=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Epoch 1, Loss: 3.466932535171509, Accuracy: 1.5625, Val Loss: 3.3626649379730225, Val Accuracy: 11.60221004486084\n",
      "Iteration 20, Epoch 2, Loss: 0.35211580991744995, Accuracy: 87.5, Val Loss: 0.93828946352005, Val Accuracy: 70.1657485961914\n",
      "Iteration 40, Epoch 3, Loss: 0.16350938379764557, Accuracy: 95.3125, Val Loss: 0.5835276246070862, Val Accuracy: 85.63536071777344\n",
      "Iteration 60, Epoch 4, Loss: 0.08093790709972382, Accuracy: 98.4375, Val Loss: 0.4751368463039398, Val Accuracy: 90.05525207519531\n",
      "Iteration 80, Epoch 5, Loss: 0.05999099463224411, Accuracy: 100.0, Val Loss: 0.39827847480773926, Val Accuracy: 90.60773468017578\n",
      "Iteration 100, Epoch 6, Loss: 0.04303440824151039, Accuracy: 98.4375, Val Loss: 0.35022643208503723, Val Accuracy: 90.60773468017578\n",
      "Iteration 120, Epoch 7, Loss: 0.03295818716287613, Accuracy: 100.0, Val Loss: 0.3148234784603119, Val Accuracy: 91.16021728515625\n",
      "Iteration 140, Epoch 8, Loss: 0.0257298294454813, Accuracy: 100.0, Val Loss: 0.2879813611507416, Val Accuracy: 92.26519775390625\n",
      "Iteration 160, Epoch 9, Loss: 0.020646000280976295, Accuracy: 100.0, Val Loss: 0.26867881417274475, Val Accuracy: 92.81768035888672\n",
      "Iteration 180, Epoch 10, Loss: 0.0169994980096817, Accuracy: 100.0, Val Loss: 0.2557024657726288, Val Accuracy: 92.81768035888672\n"
     ]
    }
   ],
   "source": [
    "# собтвенно точность 99/93 попробую нормализацию\n",
    "# как бы я не растыкивал нормализацию эффекта ~0\n",
    "\n",
    "def model_init_fn():\n",
    "    input_shape = (8,8,1)\n",
    "    channel_1, channel_2, num_classes = 32, 16, 10\n",
    "    layers = [\n",
    "        tf.keras.layers.Conv2D(channel_1, 5, activation=\"relu\", padding=\"same\", input_shape=input_shape),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Conv2D(channel_2, 3, activation=\"relu\", padding=\"same\"),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ]\n",
    "    model = tf.keras.Sequential(layers)\n",
    "    return model\n",
    "\n",
    "train_part34(model_init_fn, optimizer_init_fn, num_epochs=10, is_training=True, print_every=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Epoch 1, Loss: 3.9931769371032715, Accuracy: 7.8125, Val Loss: 2.6365721225738525, Val Accuracy: 3.867403507232666\n",
      "Iteration 20, Epoch 2, Loss: 1.212716817855835, Accuracy: 68.75, Val Loss: 1.1363452672958374, Val Accuracy: 81.21546936035156\n",
      "Iteration 40, Epoch 3, Loss: 0.6065095067024231, Accuracy: 81.25, Val Loss: 0.5764067769050598, Val Accuracy: 85.08287048339844\n",
      "Iteration 60, Epoch 4, Loss: 0.3889661431312561, Accuracy: 85.9375, Val Loss: 0.45435282588005066, Val Accuracy: 85.63536071777344\n",
      "Iteration 80, Epoch 5, Loss: 0.24213647842407227, Accuracy: 93.75, Val Loss: 0.37123748660087585, Val Accuracy: 89.50276184082031\n",
      "Iteration 100, Epoch 6, Loss: 0.20273646712303162, Accuracy: 92.1875, Val Loss: 0.3636649549007416, Val Accuracy: 90.05525207519531\n",
      "Iteration 120, Epoch 7, Loss: 0.19075293838977814, Accuracy: 89.0625, Val Loss: 0.34534427523612976, Val Accuracy: 92.81768035888672\n",
      "Iteration 140, Epoch 8, Loss: 0.14698359370231628, Accuracy: 93.75, Val Loss: 0.3275569975376129, Val Accuracy: 92.81768035888672\n",
      "Iteration 160, Epoch 9, Loss: 0.09044896066188812, Accuracy: 96.875, Val Loss: 0.3260759711265564, Val Accuracy: 92.26519775390625\n",
      "Iteration 180, Epoch 10, Loss: 0.1646517813205719, Accuracy: 96.875, Val Loss: 0.3675680160522461, Val Accuracy: 91.71270751953125\n"
     ]
    }
   ],
   "source": [
    "# собтвенно точность 99/93 попробую немного дропаут слои\n",
    "# при различном rate - эффект такой же как от нормализации - никакой\n",
    "\n",
    "def model_init_fn():\n",
    "    input_shape = (8,8,1)\n",
    "    channel_1, channel_2, num_classes = 32, 16, 10\n",
    "    layers = [\n",
    "        tf.keras.layers.Conv2D(channel_1, 5, activation=\"relu\", padding=\"same\", input_shape=input_shape),\n",
    "        tf.keras.layers.Dropout(rate=0.3),\n",
    "        tf.keras.layers.Conv2D(channel_2, 3, activation=\"relu\", padding=\"same\"),\n",
    "        tf.keras.layers.Dropout(rate=0.3),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ]\n",
    "    model = tf.keras.Sequential(layers)\n",
    "    return model\n",
    "\n",
    "train_part34(model_init_fn, optimizer_init_fn, num_epochs=10, is_training=True, print_every=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Epoch 1, Loss: 3.6793887615203857, Accuracy: 9.375, Val Loss: 3.46462082862854, Val Accuracy: 10.497238159179688\n",
      "Iteration 20, Epoch 2, Loss: 0.46564823389053345, Accuracy: 90.625, Val Loss: 1.846177101135254, Val Accuracy: 33.149169921875\n",
      "Iteration 40, Epoch 3, Loss: 0.19027945399284363, Accuracy: 93.75, Val Loss: 1.4553037881851196, Val Accuracy: 50.828731536865234\n",
      "Iteration 60, Epoch 4, Loss: 0.1075747162103653, Accuracy: 98.4375, Val Loss: 0.7992900013923645, Val Accuracy: 76.24309539794922\n",
      "Iteration 80, Epoch 5, Loss: 0.06554713845252991, Accuracy: 98.4375, Val Loss: 0.6055193543434143, Val Accuracy: 82.8729248046875\n",
      "Iteration 100, Epoch 6, Loss: 0.05200958997011185, Accuracy: 98.4375, Val Loss: 0.5208153128623962, Val Accuracy: 87.2928237915039\n",
      "Iteration 120, Epoch 7, Loss: 0.042390722781419754, Accuracy: 98.4375, Val Loss: 0.40499815344810486, Val Accuracy: 89.50276184082031\n",
      "Iteration 140, Epoch 8, Loss: 0.03053460456430912, Accuracy: 100.0, Val Loss: 0.35817790031433105, Val Accuracy: 89.50276184082031\n",
      "Iteration 160, Epoch 9, Loss: 0.024259809404611588, Accuracy: 100.0, Val Loss: 0.33733025193214417, Val Accuracy: 90.05525207519531\n",
      "Iteration 180, Epoch 10, Loss: 0.01979759708046913, Accuracy: 100.0, Val Loss: 0.31020066142082214, Val Accuracy: 90.60773468017578\n"
     ]
    }
   ],
   "source": [
    "# собтвенно точность 99/93 попробую немного дропаут слои\n",
    "# еще поэкспериментирую с пулингом\n",
    "# как сам пулинг, так и другие миксы с ним не дали особых результатов\n",
    "\n",
    "def model_init_fn():\n",
    "    input_shape = (8,8,1)\n",
    "    channel_1, channel_2, num_classes = 32, 16, 10\n",
    "    layers = [\n",
    "        tf.keras.layers.Conv2D(channel_1, 5, activation=\"relu\", padding=\"same\", input_shape=input_shape),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Conv2D(channel_2, 3, activation=\"relu\", padding=\"same\"),\n",
    "        tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(1, 1), padding='valid'),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ]\n",
    "    model = tf.keras.Sequential(layers)\n",
    "    return model\n",
    "\n",
    "train_part34(model_init_fn, optimizer_init_fn, num_epochs=10, is_training=True, print_every=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Epoch 1, Loss: 3.910141706466675, Accuracy: 9.375, Val Loss: 3.1600263118743896, Val Accuracy: 11.60221004486084\n",
      "Iteration 20, Epoch 2, Loss: 0.48923054337501526, Accuracy: 85.9375, Val Loss: 1.3396177291870117, Val Accuracy: 53.038673400878906\n",
      "Iteration 40, Epoch 3, Loss: 0.26783299446105957, Accuracy: 92.1875, Val Loss: 1.0259990692138672, Val Accuracy: 65.19337463378906\n",
      "Iteration 60, Epoch 4, Loss: 0.13305680453777313, Accuracy: 98.4375, Val Loss: 0.7247111201286316, Val Accuracy: 76.79557800292969\n",
      "Iteration 80, Epoch 5, Loss: 0.0739607959985733, Accuracy: 96.875, Val Loss: 0.5561733841896057, Val Accuracy: 82.8729248046875\n",
      "Iteration 100, Epoch 6, Loss: 0.05592239648103714, Accuracy: 98.4375, Val Loss: 0.4755704700946808, Val Accuracy: 85.08287048339844\n",
      "Iteration 120, Epoch 7, Loss: 0.04841666668653488, Accuracy: 98.4375, Val Loss: 0.39910462498664856, Val Accuracy: 87.84529876708984\n",
      "Iteration 140, Epoch 8, Loss: 0.03279917687177658, Accuracy: 100.0, Val Loss: 0.363839715719223, Val Accuracy: 89.50276184082031\n",
      "Iteration 160, Epoch 9, Loss: 0.0273731742054224, Accuracy: 100.0, Val Loss: 0.352710485458374, Val Accuracy: 89.50276184082031\n",
      "Iteration 180, Epoch 10, Loss: 0.021083341911435127, Accuracy: 100.0, Val Loss: 0.31339940428733826, Val Accuracy: 91.16021728515625\n",
      "Iteration 200, Epoch 11, Loss: 0.018148699775338173, Accuracy: 100.0, Val Loss: 0.2878905236721039, Val Accuracy: 91.71270751953125\n",
      "Iteration 220, Epoch 12, Loss: 0.014721455983817577, Accuracy: 100.0, Val Loss: 0.2823772132396698, Val Accuracy: 91.71270751953125\n",
      "Iteration 240, Epoch 13, Loss: 0.012699555605649948, Accuracy: 100.0, Val Loss: 0.2759864628314972, Val Accuracy: 91.71270751953125\n",
      "Iteration 260, Epoch 14, Loss: 0.011030144058167934, Accuracy: 100.0, Val Loss: 0.2700698673725128, Val Accuracy: 92.26519775390625\n",
      "Iteration 280, Epoch 15, Loss: 0.00962086021900177, Accuracy: 100.0, Val Loss: 0.26695120334625244, Val Accuracy: 92.81768035888672\n",
      "Iteration 300, Epoch 16, Loss: 0.00847192108631134, Accuracy: 100.0, Val Loss: 0.2647450268268585, Val Accuracy: 92.81768035888672\n",
      "Iteration 320, Epoch 17, Loss: 0.007533540483564138, Accuracy: 100.0, Val Loss: 0.26381680369377136, Val Accuracy: 92.81768035888672\n",
      "Iteration 340, Epoch 18, Loss: 0.006723790429532528, Accuracy: 100.0, Val Loss: 0.2633534371852875, Val Accuracy: 92.81768035888672\n",
      "Iteration 360, Epoch 19, Loss: 0.006053075194358826, Accuracy: 100.0, Val Loss: 0.26349538564682007, Val Accuracy: 92.81768035888672\n",
      "Iteration 380, Epoch 20, Loss: 0.005475670099258423, Accuracy: 100.0, Val Loss: 0.26374244689941406, Val Accuracy: 92.81768035888672\n"
     ]
    }
   ],
   "source": [
    "# просто чек на то, что 10 эпох достаточно\n",
    "train_part34(model_init_fn, optimizer_init_fn, num_epochs=20, is_training=True, print_every=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Epoch 1, Loss: 3.2733516693115234, Accuracy: 10.9375, Val Loss: 2.3309926986694336, Val Accuracy: 15.469614028930664\n",
      "Iteration 20, Epoch 2, Loss: 0.38070738315582275, Accuracy: 87.5, Val Loss: 0.4994008541107178, Val Accuracy: 87.84529876708984\n",
      "Iteration 40, Epoch 3, Loss: 0.16293883323669434, Accuracy: 95.3125, Val Loss: 0.4834129810333252, Val Accuracy: 89.50276184082031\n",
      "Iteration 60, Epoch 4, Loss: 0.12343704700469971, Accuracy: 95.3125, Val Loss: 0.4230926036834717, Val Accuracy: 90.05525207519531\n",
      "Iteration 80, Epoch 5, Loss: 0.10338295996189117, Accuracy: 96.875, Val Loss: 0.3924087584018707, Val Accuracy: 88.95027923583984\n",
      "Iteration 100, Epoch 6, Loss: 0.07324284315109253, Accuracy: 96.875, Val Loss: 0.3920191526412964, Val Accuracy: 91.16021728515625\n",
      "Iteration 120, Epoch 7, Loss: 0.0702403336763382, Accuracy: 96.875, Val Loss: 0.40294113755226135, Val Accuracy: 91.16021728515625\n",
      "Iteration 140, Epoch 8, Loss: 0.07577978819608688, Accuracy: 98.4375, Val Loss: 0.38921287655830383, Val Accuracy: 90.60773468017578\n",
      "Iteration 160, Epoch 9, Loss: 0.05757603421807289, Accuracy: 98.4375, Val Loss: 0.364395409822464, Val Accuracy: 91.71270751953125\n",
      "Iteration 180, Epoch 10, Loss: 0.03534586355090141, Accuracy: 98.4375, Val Loss: 0.33054038882255554, Val Accuracy: 92.81768035888672\n"
     ]
    }
   ],
   "source": [
    "# упростим сетку, и посмотрим, что будет\n",
    "\n",
    "def model_init_fn():\n",
    "    input_shape = (8,8,1)\n",
    "    channel_1, channel_2, num_classes = 32, 16, 10\n",
    "    layers = [\n",
    "        tf.keras.layers.Conv2D(channel_1, 5, activation=\"relu\", padding=\"same\", input_shape=input_shape),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ]\n",
    "    model = tf.keras.Sequential(layers)\n",
    "    return model\n",
    "\n",
    "train_part34(model_init_fn, optimizer_init_fn, num_epochs=10, is_training=True, print_every=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Epoch 1, Loss: 3.1037650108337402, Accuracy: 4.6875, Val Loss: 2.594996929168701, Val Accuracy: 18.232044219970703\n",
      "Iteration 20, Epoch 2, Loss: 0.23567846417427063, Accuracy: 90.625, Val Loss: 0.635598361492157, Val Accuracy: 81.21546936035156\n",
      "Iteration 40, Epoch 3, Loss: 0.2023259997367859, Accuracy: 92.1875, Val Loss: 0.45637640357017517, Val Accuracy: 86.1878433227539\n",
      "Iteration 60, Epoch 4, Loss: 0.07394493371248245, Accuracy: 96.875, Val Loss: 0.4075906276702881, Val Accuracy: 88.39778900146484\n",
      "Iteration 80, Epoch 5, Loss: 0.08419841527938843, Accuracy: 98.4375, Val Loss: 0.3445611894130707, Val Accuracy: 91.16021728515625\n",
      "Iteration 100, Epoch 6, Loss: 0.048150572925806046, Accuracy: 96.875, Val Loss: 0.3348959982395172, Val Accuracy: 91.71270751953125\n",
      "Iteration 120, Epoch 7, Loss: 0.03562343120574951, Accuracy: 98.4375, Val Loss: 0.32161983847618103, Val Accuracy: 91.16021728515625\n",
      "Iteration 140, Epoch 8, Loss: 0.02911796234548092, Accuracy: 98.4375, Val Loss: 0.31212547421455383, Val Accuracy: 91.16021728515625\n",
      "Iteration 160, Epoch 9, Loss: 0.02304634265601635, Accuracy: 100.0, Val Loss: 0.3082416355609894, Val Accuracy: 92.26519775390625\n",
      "Iteration 180, Epoch 10, Loss: 0.018949154764413834, Accuracy: 100.0, Val Loss: 0.3036656677722931, Val Accuracy: 92.26519775390625\n"
     ]
    }
   ],
   "source": [
    "# тут тоже не особо полезна нормализация\n",
    "\n",
    "def model_init_fn():\n",
    "    input_shape = (8,8,1)\n",
    "    channel_1, channel_2, num_classes = 32, 16, 10\n",
    "    layers = [\n",
    "        tf.keras.layers.Conv2D(channel_1, 5, activation=\"relu\", padding=\"same\", input_shape=input_shape),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ]\n",
    "    model = tf.keras.Sequential(layers)\n",
    "    return model\n",
    "\n",
    "train_part34(model_init_fn, optimizer_init_fn, num_epochs=10, is_training=True, print_every=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Epoch 1, Loss: 2.553586959838867, Accuracy: 7.8125, Val Loss: 7.661523342132568, Val Accuracy: 21.546960830688477\n",
      "Iteration 20, Epoch 2, Loss: 0.3206251263618469, Accuracy: 92.1875, Val Loss: 0.4890342950820923, Val Accuracy: 87.2928237915039\n",
      "Iteration 40, Epoch 3, Loss: 0.14770907163619995, Accuracy: 96.875, Val Loss: 0.34876036643981934, Val Accuracy: 87.84529876708984\n",
      "Iteration 60, Epoch 4, Loss: 0.1437402069568634, Accuracy: 93.75, Val Loss: 0.4740939140319824, Val Accuracy: 87.84529876708984\n",
      "Iteration 80, Epoch 5, Loss: 0.03163708373904228, Accuracy: 98.4375, Val Loss: 0.35470107197761536, Val Accuracy: 91.71270751953125\n",
      "Iteration 100, Epoch 6, Loss: 0.07724542170763016, Accuracy: 98.4375, Val Loss: 0.3584446907043457, Val Accuracy: 90.60773468017578\n",
      "Iteration 120, Epoch 7, Loss: 0.024498146027326584, Accuracy: 98.4375, Val Loss: 0.26789236068725586, Val Accuracy: 93.37016296386719\n",
      "Iteration 140, Epoch 8, Loss: 0.01858612336218357, Accuracy: 98.4375, Val Loss: 0.326368510723114, Val Accuracy: 91.71270751953125\n",
      "Iteration 160, Epoch 9, Loss: 0.009215956553816795, Accuracy: 100.0, Val Loss: 0.26527684926986694, Val Accuracy: 93.92265319824219\n",
      "Iteration 180, Epoch 10, Loss: 0.014674510806798935, Accuracy: 100.0, Val Loss: 0.28296032547950745, Val Accuracy: 93.37016296386719\n"
     ]
    }
   ],
   "source": [
    "# еще некоторая куча тестов не дали результатов, куча разных вещей не давали вообще никакого результата, всегода +- 93\n",
    "def model_init_fn():\n",
    "    input_shape = (8,8,1)\n",
    "    channel_1, channel_2, num_classes = 128, 256, 10\n",
    "    layers = [\n",
    "        tf.keras.layers.Conv2D(channel_1, 5, activation=\"relu\", padding=\"same\", input_shape=input_shape),\n",
    "        tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(1, 1), padding='valid'),\n",
    "        tf.keras.layers.Conv2D(channel_2, 5, activation=\"relu\", padding=\"same\", input_shape=input_shape),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ]\n",
    "    model = tf.keras.Sequential(layers)\n",
    "    return model\n",
    "\n",
    "train_part34(model_init_fn, optimizer_init_fn, num_epochs=10, is_training=True, print_every=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Epoch 1, Loss: 2.9153409004211426, Accuracy: 14.0625, Val Loss: 3.117932081222534, Val Accuracy: 18.784530639648438\n",
      "Iteration 20, Epoch 2, Loss: 0.32756683230400085, Accuracy: 95.3125, Val Loss: 0.5580245852470398, Val Accuracy: 82.32044219970703\n",
      "Iteration 40, Epoch 3, Loss: 0.11920501291751862, Accuracy: 93.75, Val Loss: 0.4073506295681, Val Accuracy: 89.50276184082031\n",
      "Iteration 60, Epoch 4, Loss: 0.12326538562774658, Accuracy: 95.3125, Val Loss: 0.37492576241493225, Val Accuracy: 89.50276184082031\n",
      "Iteration 80, Epoch 5, Loss: 0.0839371383190155, Accuracy: 98.4375, Val Loss: 0.49528130888938904, Val Accuracy: 89.50276184082031\n",
      "Iteration 100, Epoch 6, Loss: 0.0971813052892685, Accuracy: 96.875, Val Loss: 0.3896768391132355, Val Accuracy: 92.26519775390625\n",
      "Iteration 120, Epoch 7, Loss: 0.05998474732041359, Accuracy: 98.4375, Val Loss: 0.32715728878974915, Val Accuracy: 90.60773468017578\n",
      "Iteration 140, Epoch 8, Loss: 0.04062815010547638, Accuracy: 98.4375, Val Loss: 0.27616846561431885, Val Accuracy: 90.60773468017578\n",
      "Iteration 160, Epoch 9, Loss: 0.011559830978512764, Accuracy: 100.0, Val Loss: 0.2584614157676697, Val Accuracy: 92.81768035888672\n",
      "Iteration 180, Epoch 10, Loss: 0.006808103993535042, Accuracy: 100.0, Val Loss: 0.23035156726837158, Val Accuracy: 92.81768035888672\n"
     ]
    }
   ],
   "source": [
    "# изменения размерностей слоев тоже никуда не превели\n",
    "\n",
    "def model_init_fn():\n",
    "    input_shape = (8,8,1)\n",
    "    channel_1, channel_2, num_classes = 128, 64, 10\n",
    "    layers = [\n",
    "        tf.keras.layers.Conv2D(channel_1, 5, activation=\"relu\", padding=\"same\", input_shape=input_shape),\n",
    "        tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(1, 1), padding='valid'),\n",
    "        tf.keras.layers.Conv2D(channel_2, 5, activation=\"relu\", padding=\"same\", input_shape=input_shape),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ]\n",
    "    model = tf.keras.Sequential(layers)\n",
    "    return model\n",
    "\n",
    "train_part34(model_init_fn, optimizer_init_fn, num_epochs=10, is_training=True, print_every=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Epoch 1, Loss: 10.436516761779785, Accuracy: 4.6875, Val Loss: 9.603763580322266, Val Accuracy: 6.077348232269287\n",
      "Iteration 100, Epoch 6, Loss: 0.21325251460075378, Accuracy: 95.3125, Val Loss: 0.7091392874717712, Val Accuracy: 86.1878433227539\n",
      "Iteration 200, Epoch 11, Loss: 0.1154417023062706, Accuracy: 96.875, Val Loss: 0.5377813577651978, Val Accuracy: 88.95027923583984\n",
      "Iteration 300, Epoch 16, Loss: 0.08661089837551117, Accuracy: 96.875, Val Loss: 0.4578511714935303, Val Accuracy: 91.16021728515625\n",
      "Iteration 400, Epoch 21, Loss: 0.06255783885717392, Accuracy: 96.875, Val Loss: 0.424409955739975, Val Accuracy: 91.71270751953125\n",
      "Iteration 500, Epoch 26, Loss: 0.04466624557971954, Accuracy: 98.4375, Val Loss: 0.41194331645965576, Val Accuracy: 92.26519775390625\n",
      "Iteration 600, Epoch 31, Loss: 0.03330942243337631, Accuracy: 98.4375, Val Loss: 0.40820053219795227, Val Accuracy: 92.81768035888672\n",
      "Iteration 700, Epoch 36, Loss: 0.025487396866083145, Accuracy: 100.0, Val Loss: 0.4069206416606903, Val Accuracy: 93.37016296386719\n",
      "Iteration 800, Epoch 41, Loss: 0.0201509241014719, Accuracy: 100.0, Val Loss: 0.408273845911026, Val Accuracy: 92.81768035888672\n",
      "Iteration 900, Epoch 46, Loss: 0.015937555581331253, Accuracy: 100.0, Val Loss: 0.4100264608860016, Val Accuracy: 92.26519775390625\n",
      "Iteration 1000, Epoch 51, Loss: 0.013209939002990723, Accuracy: 100.0, Val Loss: 0.41403400897979736, Val Accuracy: 92.26519775390625\n",
      "Iteration 1100, Epoch 56, Loss: 0.0110827861353755, Accuracy: 100.0, Val Loss: 0.4173339903354645, Val Accuracy: 92.26519775390625\n",
      "Iteration 1200, Epoch 61, Loss: 0.009256979450583458, Accuracy: 100.0, Val Loss: 0.4205514192581177, Val Accuracy: 92.81768035888672\n",
      "Iteration 1300, Epoch 66, Loss: 0.007836750708520412, Accuracy: 100.0, Val Loss: 0.4236767292022705, Val Accuracy: 93.37016296386719\n",
      "Iteration 1400, Epoch 71, Loss: 0.006799123249948025, Accuracy: 100.0, Val Loss: 0.4264806807041168, Val Accuracy: 93.37016296386719\n",
      "Iteration 1500, Epoch 76, Loss: 0.005975282751023769, Accuracy: 100.0, Val Loss: 0.4317632019519806, Val Accuracy: 93.37016296386719\n",
      "Iteration 1600, Epoch 81, Loss: 0.005258414428681135, Accuracy: 100.0, Val Loss: 0.4367431700229645, Val Accuracy: 93.92265319824219\n",
      "Iteration 1700, Epoch 86, Loss: 0.00464068166911602, Accuracy: 100.0, Val Loss: 0.44097280502319336, Val Accuracy: 93.92265319824219\n",
      "Iteration 1800, Epoch 91, Loss: 0.004114754963666201, Accuracy: 100.0, Val Loss: 0.44471099972724915, Val Accuracy: 93.92265319824219\n",
      "Iteration 1900, Epoch 96, Loss: 0.0036348314024508, Accuracy: 100.0, Val Loss: 0.44880303740501404, Val Accuracy: 93.37016296386719\n"
     ]
    }
   ],
   "source": [
    "# ну и конечно же я помню результаты первых лаб о посему... толка оказалось 0\n",
    "# продолжать так можно долго, но думаю, что я остановлюсь\n",
    "def model_init_fn():\n",
    "    input_shape = (8,8,1)\n",
    "    channel_1, channel_2, num_classes = 128, 64, 10\n",
    "    layers = [\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ]\n",
    "    model = tf.keras.Sequential(layers)\n",
    "    return model\n",
    "\n",
    "train_part34(model_init_fn, optimizer_init_fn, num_epochs=100, is_training=True, print_every=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
